{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ChromaX","text":"<p>ChromaX is an experimental utilities package for Chroma vector database.</p>"},{"location":"embeddings/","title":"Embeddings","text":""},{"location":"embeddings/#onnx-runtime","title":"Onnx Runtime","text":"<p>A convenient way to run onnx models to generate embeddings.</p>"},{"location":"embeddings/#with-huggingface-model","title":"With HuggingFace Model","text":"<p>The following example shows how to use the embedding function to download a model from HuggingFace and use it to generate embeddings.</p> <p>Note: You will need to install <code>huggingface_hub</code> (<code>pip install huggingface_hub</code>) to download the model.</p> <pre><code>from chromadbx.embeddings.onnx import OnnxRuntimeEmbeddings\nef=OnnxRuntimeEmbeddings(model_path=\"snowflake/arctic-embed-s\",preferred_providers=[\"CPUExecutionProvider\"],hf_download=True)\n\nef([\"text\"])\n</code></pre>"},{"location":"embeddings/#with-local-model","title":"With Local Model","text":"<p>Download a model:</p> <pre><code>mkdir -p ~/.cache/models/hf\ngit clone https://huggingface.co/snowflake/arctic-embed-s ~/.cache/models/hf/snowflake-arctic-embed-s\n</code></pre> <p>Alternatively use HF CLI:</p> <pre><code>pip install -U \"huggingface_hub[cli]\"\nhuggingface-cli download snowflake/arctic-embed-s --local-dir snowflake-arctic-embed-s\n</code></pre> <pre><code>from chromadbx.embeddings.onnx import OnnxRuntimeEmbeddings\nimport chromadb\n\n# adjust the model path to the path where you downloaded the model\n# We use the CPUExecutionProvider, adjust it to your liking or leave empty to let onnx choose the most appropriate provider\nef = OnnxRuntimeEmbeddings(model_path=f\"snowflake-arctic-embed-s\", preferred_providers=[\"CPUExecutionProvider\"])\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#llamacpp","title":"Llama.cpp","text":"<p>\u26a0\ufe0f Llama.cpp embedding function is still in early development. Please report any problems you may have by raising an issue.</p> <p>A convenient way to run llama.cpp models to generate embeddings.</p>"},{"location":"embeddings/#with-hf-model","title":"With HF Model","text":"<p>The embedding function supports downloading models directly from HuggingFace Hub.</p> <pre><code>import chromadb\nfrom chromadbx.embeddings.llamacpp import LlamaCppEmbeddingFunction\n\nef = LlamaCppEmbeddingFunction(model_path=\"yixuan-chia/snowflake-arctic-embed-s-GGUF\",\n                               hf_file_name=\"snowflake-arctic-embed-s-F32.gguf\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#with-local-model_1","title":"With Local Model","text":"<p>Download a model:</p> <pre><code>pip install -U \"huggingface_hub[cli]\"\nhuggingface-cli download ChristianAzinn/snowflake-arctic-embed-s-gguf --include=snowflake-arctic-embed-s-f16.GGUF --local-dir snowflake-arctic-embed-s\n</code></pre> <pre><code>import chromadb\nfrom chromadbx.embeddings.llamacpp import LlamaCppEmbeddingFunction\n\nef = LlamaCppEmbeddingFunction(model_path=\"snowflake-arctic-embed-s/snowflake-arctic-embed-s-f16.GGUF\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#google-vertex-ai","title":"Google Vertex AI","text":"<p>A convenient way to run Google Vertex AI models to generate embeddings.</p> <p>Google Vertex AI uses variety of authentication methods. The most secure is either service account key file or Google Application Default Credentials.</p> <pre><code>import chromadb\nfrom chromadbx.embeddings.google import GoogleVertexAiEmbeddings\n\nef = GoogleVertexAiEmbeddings()\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#auth-with-service-account-key-file","title":"Auth with service account key file","text":"<pre><code>from chromadbx.embeddings.google import GoogleVertexAiEmbeddings\nfrom google.oauth2 import service_account\n\ncredentials = service_account.Credentials.from_service_account_file(\"path/to/service-account-key.json\")\nef = GoogleVertexAiEmbeddings(credentials=credentials)\n\nef([\"hello world\", \"goodbye world\"])\n</code></pre>"},{"location":"embeddings/#mistral-ai","title":"Mistral AI","text":"<p>A convenient way to generate embeddings using Mistral AI models.</p> <pre><code>import chromadb\nfrom chromadbx.embeddings.mistral import MistralAiEmbeddings\n\nef = MistralAiEmbeddings()\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\ncol.query(query_texts=[\"lorem ipsum...\"], n_results=2)\n</code></pre>"},{"location":"embeddings/#cloudflare-workers-ai","title":"Cloudflare Workers AI","text":"<p>A convenient way to generate embeddings using Cloudflare Workers AI models.</p> <p>Using with Account ID and API Token:</p> <pre><code>import os\nimport chromadb\nfrom chromadbx.embeddings.cloudflare import CloudflareWorkersAIEmbeddings\n\nef = CloudflareWorkersAIEmbeddings(\n    model_name=\"@cf/baai/bge-base-en-v1.5\",\n    api_token=os.getenv(\"CF_API_TOKEN\"),\n    account_id=os.getenv(\"CF_ACCOUNT_ID\")\n)\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\ncol.query(query_texts=[\"lorem ipsum...\"], n_results=2)\n</code></pre> <p>Using with Gateway Endpoint:</p> <pre><code>import os\nfrom chromadbx.embeddings.cloudflare import CloudflareWorkersAIEmbeddings\n\nef = CloudflareWorkersAIEmbeddings(\n    model_name=\"@cf/baai/bge-base-en-v1.5\",\n    api_token=os.getenv(\"CF_API_TOKEN\"),\n    gateway_url=os.getenv(\"CF_GATEWAY_ENDPOINT\") # \"https://gateway.ai.cloudflare.com/v1/[account_id]/[project]/workers-ai\"\n)\n\n# ... rest of the code\n</code></pre>"}]}