{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ChromaX","text":"<p>ChromaX is an experimental utilities package for Chroma vector database.</p>"},{"location":"embeddings/","title":"Embeddings","text":""},{"location":"embeddings/#onnx-runtime","title":"Onnx Runtime","text":"<p>A convenient way to run onnx models to generate embeddings.</p>"},{"location":"embeddings/#with-huggingface-model","title":"With HuggingFace Model","text":"<p>The following example shows how to use the embedding function to download a model from HuggingFace and use it to generate embeddings.</p> <p>Note: You will need to install <code>huggingface_hub</code> (<code>pip install huggingface_hub</code>) to download the model.</p> <pre><code>from chromadbx.embeddings.onnx import OnnxRuntimeEmbeddings\nef=OnnxRuntimeEmbeddings(model_path=\"snowflake/arctic-embed-s\",preferred_providers=[\"CPUExecutionProvider\"],hf_download=True)\n\nef([\"text\"])\n</code></pre>"},{"location":"embeddings/#with-local-model","title":"With Local Model","text":"<p>Download a model:</p> <pre><code>mkdir -p ~/.cache/models/hf\ngit clone https://huggingface.co/snowflake/arctic-embed-s ~/.cache/models/hf/snowflake-arctic-embed-s\n</code></pre> <p>Alternatively use HF CLI:</p> <pre><code>pip install -U \"huggingface_hub[cli]\"\nhuggingface-cli download snowflake/arctic-embed-s --local-dir snowflake-arctic-embed-s\n</code></pre> <pre><code>from chromadbx.embeddings.onnx import OnnxRuntimeEmbeddings\nimport chromadb\n\n# adjust the model path to the path where you downloaded the model\n# We use the CPUExecutionProvider, adjust it to your liking or leave empty to let onnx choose the most appropriate provider\nef = OnnxRuntimeEmbeddings(model_path=f\"snowflake-arctic-embed-s\", preferred_providers=[\"CPUExecutionProvider\"])\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#llamacpp","title":"Llama.cpp","text":"<p>\u26a0\ufe0f Llama.cpp embedding function is still in early development. Please report any problems you may have by raising an issue.</p> <p>A convenient way to run llama.cpp models to generate embeddings.</p>"},{"location":"embeddings/#with-hf-model","title":"With HF Model","text":"<p>The embedding function supports downloading models directly from HuggingFace Hub.</p> <pre><code>import chromadb\nfrom chromadbx.embeddings.llamacpp import LlamaCppEmbeddingFunction\n\nef = LlamaCppEmbeddingFunction(model_path=\"yixuan-chia/snowflake-arctic-embed-s-GGUF\",\n                               hf_file_name=\"snowflake-arctic-embed-s-F32.gguf\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#with-local-model_1","title":"With Local Model","text":"<p>Download a model:</p> <pre><code>pip install -U \"huggingface_hub[cli]\"\nhuggingface-cli download ChristianAzinn/snowflake-arctic-embed-s-gguf --include=snowflake-arctic-embed-s-f16.GGUF --local-dir snowflake-arctic-embed-s\n</code></pre> <pre><code>import chromadb\nfrom chromadbx.embeddings.llamacpp import LlamaCppEmbeddingFunction\n\nef = LlamaCppEmbeddingFunction(model_path=\"snowflake-arctic-embed-s/snowflake-arctic-embed-s-f16.GGUF\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#google-vertex-ai","title":"Google Vertex AI","text":"<p>A convenient way to run Google Vertex AI models to generate embeddings.</p> <p>Google Vertex AI uses variety of authentication methods. The most secure is either service account key file or Google Application Default Credentials.</p>"},{"location":"embeddings/#auth-with-gcloud","title":"Auth with gcloud","text":"<p>The gloud auth will happen automatically so you do not need to provide any credentials to the embedding function.</p> <pre><code>import chromadb\nfrom chromadbx.embeddings.google import GoogleVertexAiEmbeddings\n\nef = GoogleVertexAiEmbeddings()\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#auth-with-service-account-key-file","title":"Auth with service account key file","text":"<pre><code>from chromadbx.embeddings.google import GoogleVertexAiEmbeddings\nfrom google.oauth2 import service_account\n\ncredentials = service_account.Credentials.from_service_account_file(\"path/to/service-account-key.json\")\nef = GoogleVertexAiEmbeddings(credentials=credentials)\n\nef([\"hello world\", \"goodbye world\"])\n</code></pre>"},{"location":"embeddings/#auth-with-api-key","title":"Auth with API Key","text":"<pre><code>from chromadbx.embeddings.google import GoogleVertexAiEmbeddings\n\nef = GoogleVertexAiEmbeddings(api_key=\"API_KEY\", project_id=\"MY_PROJECT_ID\")\n\nef([\"hello world\", \"goodbye world\"])\n</code></pre>"},{"location":"embeddings/#mistral-ai","title":"Mistral AI","text":"<p>A convenient way to generate embeddings using Mistral AI models.</p> <pre><code>import chromadb\nfrom chromadbx.embeddings.mistral import MistralAiEmbeddings\n\nef = MistralAiEmbeddings()\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\ncol.query(query_texts=[\"lorem ipsum...\"], n_results=2)\n</code></pre>"},{"location":"embeddings/#cloudflare-workers-ai","title":"Cloudflare Workers AI","text":"<p>A convenient way to generate embeddings using Cloudflare Workers AI models.</p> <p>Using with Account ID and API Token:</p> <pre><code>import os\nimport chromadb\nfrom chromadbx.embeddings.cloudflare import CloudflareWorkersAIEmbeddings\n\nef = CloudflareWorkersAIEmbeddings(\n    model_name=\"@cf/baai/bge-base-en-v1.5\",\n    api_token=os.getenv(\"CF_API_TOKEN\"),\n    account_id=os.getenv(\"CF_ACCOUNT_ID\")\n)\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\ncol.query(query_texts=[\"lorem ipsum...\"], n_results=2)\n</code></pre> <p>Using with Gateway Endpoint:</p> <pre><code>import os\nfrom chromadbx.embeddings.cloudflare import CloudflareWorkersAIEmbeddings\n\nef = CloudflareWorkersAIEmbeddings(\n    model_name=\"@cf/baai/bge-base-en-v1.5\",\n    api_token=os.getenv(\"CF_API_TOKEN\"),\n    gateway_url=os.getenv(\"CF_GATEWAY_ENDPOINT\") # \"https://gateway.ai.cloudflare.com/v1/[account_id]/[project]/workers-ai\"\n)\n\n# ... rest of the code\n</code></pre>"},{"location":"embeddings/#spacy","title":"Spacy","text":"<p>A convenient way to generate embeddings using Spacy models.</p> <p>To use Spacy, you need to install the <code>spacy</code> package.</p> <pre><code>pip install spacy\n</code></pre> <p>You will also need to download the model you want to use.</p> <pre><code>python -m spacy download en_core_web_lg\n</code></pre> <pre><code>import chromadb\nfrom chromadbx.embeddings.spacy import SpacyEmbeddingFunction\n\nef = SpacyEmbeddingFunction(model_name=\"en_core_web_lg\")\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#together","title":"Together","text":"<p>A convenient way to generate embeddings using Together models. To use the embedding function, you need to install the <code>together</code> package.</p> <pre><code>pip install together\n</code></pre> <p>Additionally, you need to get an API key from Together.</p> <pre><code>import os\nimport chromadb\nfrom chromadbx.embeddings.together import TogetherEmbeddingFunction\n\nef = TogetherEmbeddingFunction(api_key=os.getenv(\"TOGETHER_API_KEY\"))\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre>"},{"location":"embeddings/#nomic","title":"Nomic","text":"<p>A convenient way to generate embeddings using Nomic models.</p> <p>To use the embedding function, you need to install the <code>nomic</code> package.</p> <pre><code>pip install nomic\n</code></pre> <p>Before you proceed, you will need to create an account and get an API key from Nomic.</p> <pre><code>import os\nimport chromadb\nfrom chromadbx.embeddings.nomic import NomicEmbeddingFunction\n\nef = NomicEmbeddingFunction(api_key=os.getenv(\"NOMIC_API_KEY\"))\n\nclient = chromadb.Client()\n\ncol = client.get_or_create_collection(\"test\", embedding_function=ef)\n\ncol.add(ids=[\"id1\", \"id2\", \"id3\"], documents=[\"lorem ipsum...\", \"doc2\", \"doc3\"])\n</code></pre> <p>[!TIP] Nomic supports dimensionality reduction which can save storage space required in Chroma without degrading retrieval quality. To take advantage of this use <code>dimensionality</code> parameter in the <code>NomicEmbeddingFunction</code> class.</p>"},{"location":"reranking/","title":"Reranking","text":"<p>Reranking is a process of reordering a list of items based on their relevance to a query. This project supports reranking of documents and query results.</p> <pre><code>from chromadbx.reranking.some_reranker import SomeReranker\nimport chromadb\nsome_reranker = SomeReranker()\n\nclient = chromadb.Client()\n\ncollection = client.get_collection(\"documents\")\n\nresults = collection.query(\n    query_texts=[\"What is the capital of the United States?\"],\n    n_results=10,\n)\n\nreranked_results = some_reranker(results)\n\nprint(\"Documents:\", reranked_results[\"documents\"][0])\nprint(\"Distances:\", reranked_results[\"distances\"][0])\nprint(\"Reranked distances:\", reranked_results[\"ranked_distances\"][some_reranker.id()][0])\n</code></pre> <p>[!NOTE] It is our intent that all officially supported reranking functions shall return distances instead of scores to be consistent with the core Chroma project. However, this is not a hard requirement and you should check the documentation for each reranking function you plan to use.</p> <p>The following reranking functions are supported:</p> Reranking Function Official Docs Cohere docs"},{"location":"reranking/#cohere","title":"Cohere","text":"<p>Cohere reranking function offers a convinient wrapper around the Cohere API to rerank documents and query results. For more information on Cohere reranking, visit the official docs or API docs.</p> <p>You need to install the <code>cohere</code> package to use this reranking function.</p> <pre><code>pip install cohere # or poetry add cohere\n</code></pre> <p>Before using the reranking function, you need to obtain Cohere API key and set the <code>COHERE_API_KEY</code> environment variable.</p> <p>[!TIP]  By default, the reranking function will return distances. If you need to get the raw scores, set the <code>raw_scores</code> parameter to <code>True</code>.</p> <pre><code>import os\nimport chromadb\nfrom chromadbx.reranking import CohereReranker\n\ncohere = CohereReranker(api_key=os.getenv(\"COHERE_API_KEY\"))\n\nclient = chromadb.Client()\n\ncollection = client.get_collection(\"documents\")\n\nresults = collection.query(\n    query_texts=[\"What is the capital of the United States?\"],\n    n_results=10,\n)\n\nreranked_results = cohere(results)\n</code></pre> <p>Available options:</p> <ul> <li><code>api_key</code>: The Cohere API key.</li> <li><code>model_name</code>: The Cohere model to use for reranking. Defaults to <code>rerank-v3.5</code>.</li> <li><code>raw_scores</code>: Whether to return the raw scores from the Cohere API. Defaults to <code>False</code>.</li> <li><code>top_n</code>: The number of results to return. Defaults to <code>None</code>.</li> <li><code>max_tokens_per_document</code>: The maximum number of tokens per document. Defaults to <code>4096</code>.</li> <li><code>timeout</code>: The timeout for the Cohere API request. Defaults to <code>60</code>.</li> <li><code>max_retries</code>: The maximum number of retries for the Cohere API request. Defaults to <code>3</code>.</li> <li><code>additional_headers</code>: Additional headers to include in the Cohere API request. Defaults to <code>None</code>.</li> </ul>"}]}